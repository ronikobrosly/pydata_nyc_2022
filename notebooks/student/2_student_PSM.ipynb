{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fc308d6-3f49-41e9-b66a-a1b6da78d2fc",
   "metadata": {},
   "source": [
    "# Notebook 2 - Propensity Score Matching (student notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ce39a2-5c9c-4f00-8abc-a1abf90768bb",
   "metadata": {},
   "source": [
    "\n",
    "In this notebook we'll look at a classic economics dataset (LaLonde R, 1986) and try to calculate propensity scores and estimate a basic causal treatment effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884d54e5-20d3-401a-ad3c-ca9a7f135e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a512ca09-969f-408a-9171-b34816477a45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Windows users: replace the following line with `df = pd.read_csv(r\"..\\..\\data\\lalonde.csv\")`\n",
    "df = pd.read_csv(\"../../data/lalonde.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6d0d41-a96e-4203-9ce1-06a4506a9002",
   "metadata": {},
   "source": [
    "The LaLonde dataset should contain the following 12 columns. This is data from a set of individuals received a job training course (that is the treatment). It was hypothesized that this treatment would improve their 1978 real earnings. \n",
    "\n",
    "age<br>\n",
    "   $\\;\\;\\;\\;\\;\\;$age in years.<br>\n",
    "educ<br>\n",
    "    $\\;\\;\\;\\;\\;\\;$years of schooling.<br>\n",
    "black<br>\n",
    "    $\\;\\;\\;\\;\\;\\;$indicator variable for blacks.<br>\n",
    "hisp<br>\n",
    "    $\\;\\;\\;\\;\\;\\;$indicator variable for Hispanics.<br>\n",
    "married<br>\n",
    "    $\\;\\;\\;\\;\\;\\;$indicator variable for martial status.<br>\n",
    "nodegr<br>\n",
    "    $\\;\\;\\;\\;\\;\\;$indicator variable for high school diploma.<br>\n",
    "re74<br>\n",
    "    $\\;\\;\\;\\;\\;\\;$real earnings in 1974.<br>\n",
    "re75<br>\n",
    "    $\\;\\;\\;\\;\\;\\;$real earnings in 1975.<br>\n",
    "re78<br>\n",
    "    $\\;\\;\\;\\;\\;\\;$real earnings in 1978.<br>\n",
    "u74<br>\n",
    "    $\\;\\;\\;\\;\\;\\;$indicator variable for earnings in 1974 being zero.<br>\n",
    "u75<br>\n",
    "    $\\;\\;\\;\\;\\;\\;$indicator variable for earnings in 1975 being zero.<br>\n",
    "treat<br>\n",
    "    $\\;\\;\\;\\;\\;\\;$an indicator variable for treatment status.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea6d37e-34c1-402b-a717-b69aa3d40e6e",
   "metadata": {},
   "source": [
    "Let's take a look at a few observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98712aeb-1e4f-4eb1-8f1a-b332104a02aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffb6298-e405-4b27-bf0c-8db83b0559fb",
   "metadata": {},
   "source": [
    "Adding an ID column and restricting the dataset to a few relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a1e0d8-dfa6-4d61-a638-ff571fda1035",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ID'] = range(0,445)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78bb756-84c0-4be0-8c9f-6c010a2d6dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['ID', 'age', 'educ', 'black', 'hisp', 'married', 're78', 'treat']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1063f0-2e0e-4240-9ec2-2e6c3eacfd33",
   "metadata": {},
   "source": [
    "## First, let's calculate the \"raw\" treatment effect without any adjustment for confounding "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f89855e-59f5-46ad-8232-0c672970b6af",
   "metadata": {},
   "source": [
    "This is us taking a very naive (and likely biased) look at the results. There may be a negative treatment effect, or none, or positive, because there is likely confounding going on. That's okay for now, we just want to see where we're starting from."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a4a224-aeff-4d94-9e49-c141738d8d97",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h3>EXERCISE: What are the average earnings from the treated group?</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907745d8-e5fa-4f9c-a844-54f1b9e5f012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the average earnings from the treated group\n",
    "raw_outcome_treated = _______"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc66a9f-3229-4659-b464-dc5739c4477d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h3>EXERCISE: What are the average earnings from the untreated group?</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4094b329-340e-4009-9615-24bf6ab57ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the average earnings from the untreated group\n",
    "raw_outcome_untreated = _______"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45da6f0a-a6d0-4483-a292-b422ca68ca35",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h3>EXERCISE: What is the difference between these two averages? This is the raw treatment effect.</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1193d10-6824-4110-b2bf-900761ef80d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The raw treatment effect is...\n",
    "print(round(______ - ______, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e63bf1-c4b4-4731-9cfc-46d9f22a369d",
   "metadata": {},
   "source": [
    "## Naively, it appears that the job training course (AKA the treatment) had an effect of adding an additional $1794 dollars to one's annual earning. Let's get a sense of the variability around this estimate, by calculating 95% bootstrapped confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098c50d2-3d3a-47d3-aee2-fcfe586a9423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's create a function to more elegantly pull out the raw treatment effect from a LaLonde dataset\n",
    "\n",
    "def get_raw_treatment(dataframe):\n",
    "    \"\"\"\n",
    "    Extracts a raw treatment effect from a LaLonde dataset. Assumes the treatment column is named `treat` and the outcome column is named `re78`\n",
    "    \n",
    "    Args:\n",
    "        dataframe: the pandas dataframe of interest\n",
    "        \n",
    "    Returns: Float corresponding to raw treatment effect\n",
    "    \"\"\"\n",
    "    return dataframe.groupby('treat')['re78'].mean().sort_index().diff().iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf980fa0-7b50-4424-be8b-6f1d88bd77a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's obtain 1000 bootstrap replicates of our original dataset\n",
    "\n",
    "boot_results = []\n",
    "\n",
    "for rep in range(0,10000):\n",
    "    boot_results.append(\n",
    "        get_raw_treatment(\n",
    "            df.sample(frac = 1, replace = True)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110e5208-f1bf-4130-b344-d1ec28c8443d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now find the 2.5 and 97.5 percentile of this list's values and you have the empirical, bootstrap confidence intervals\n",
    "np_boot_results = np.array(boot_results)\n",
    "print(f\"({round(np.percentile(np_boot_results, 2.5), 2)}, {round(np.percentile(np_boot_results, 97.5), 2)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd6b1c2-681b-472f-9e03-0104b3b9aa5e",
   "metadata": {},
   "source": [
    "## That's a wide confidence interval. It makes sense though, the dataset we're working with is tiny (about 450 observations)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593f084e-1041-4c96-a90f-7a199ec6258d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Now, let's try out hand at causal inference and start by creating our propensity scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d4c3af-455d-4161-9e6d-05b36043191b",
   "metadata": {},
   "source": [
    "Remember, these scores take on values [0, 1.0], and represent the probability of an individual or study unit receiving the treatment. You can generate these by creating a model that takes in all covariates and tries to predict treatment status.\n",
    "\n",
    "Let's first do some light exploratory work..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd9c323-b76c-4d11-9a14-fe1a8eecbf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a23da7-9a73-45dd-8034-c1bc9c6a4c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['educ'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f7bab5-ad09-4acb-b9f9-102e8dd248e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063d6752-f003-4647-8978-01cce51e43cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's scale our continuous covariates\n",
    "features = df[['age', 'educ']]\n",
    "\n",
    "# Use scaler of choice; here Standard scaler is used\n",
    "scaler = StandardScaler().fit(features.values)\n",
    "features = scaler.transform(features.values)\n",
    "\n",
    "df[['scaled_age', 'scaled_educ']] = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4457a6bf-58c4-4cd6-ad48-91d2048097f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516ad76e-bf2f-4941-8d67-a46514e7a360",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_model = LogisticRegression(penalty = 'none').fit(X = df[['scaled_age', 'scaled_educ', 'black', 'hisp', 'married']], y = df['treat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612d54ff-3062-49f1-a35f-12ba8a8ac192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Typically it would be good to assess model performance the usual way (creating a training and test set, calculating accuracy, recall, precision, etc.)\n",
    "# But for the purposes of this tutorial, let's skip that and assume it's a decent model\n",
    "\n",
    "df['pro_score'] = ps_model.predict_proba(X = df[['scaled_age', 'scaled_educ', 'black', 'hisp', 'married']])[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc53f88-7697-406f-9a0c-82b3b37eb89d",
   "metadata": {},
   "source": [
    "## That wasn't so bad! Now we have our propensity scores as a column in the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b419f4dc-c266-4b4d-851a-02c6729c3c6d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h3>EXERCISE: Explore the propensity scores with a univariate analysis. How are they distributed? What are the min and max values?</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38da9eb-9a8d-457d-b845-7e3144d4d305",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ea347e3-963e-4243-8ba1-2982d5536edf",
   "metadata": {},
   "source": [
    "## Now let's match up our treated and \"control\" groups based on propensity scores\n",
    "\n",
    "We're going to use \"caliper\" matching. That is, you specify a small range in which it's okay to say two propensity scores are similar enough. One standard approach is to use a fraction of the standard deviation of the propensity scores. In this example, let's use a quarter of the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e26df3b-e740-432d-a350-99987b6bb067",
   "metadata": {},
   "outputs": [],
   "source": [
    "caliper = np.std(df['pro_score']) / 4\n",
    "print(f'Caliper radius is: {round(caliper, 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef739da-c8e5-4891-9182-d9ef8a7665cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use sklearn's NearestNeighbors algorithm to clustering in 1-dimension (with the propensity scores).\n",
    "\n",
    "knn = NearestNeighbors(n_neighbors=10, radius=caliper)\n",
    "knn.fit(df['pro_score'].to_numpy().reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c293f50f-72c2-41b2-a2d7-4ef15779d4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common support distances and indexes\n",
    "distances , indexes = knn.kneighbors(\n",
    "   df['pro_score'].to_numpy().reshape(-1,1),\n",
    "    n_neighbors=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4253c53-204b-4318-a635-d13a795899e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's do the linking of treated and untreated individuals\n",
    "\n",
    "def perfom_matching(row, indexes, dataframe):\n",
    "    current_index = int(row['index'])\n",
    "    prop_score_logit = row['pro_score']\n",
    "    for idx in indexes[current_index,:]:\n",
    "        if (current_index != idx) and (row['treat'] == 1) and (dataframe.loc[idx]['treat'] == 0):\n",
    "            return int(idx)\n",
    "         \n",
    "df['matched_element'] = df.reset_index().apply(perfom_matching, axis = 1, args = (indexes, df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0cf917-206d-4e98-943f-fe4a9ad375f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any missing values in this column\n",
    "df2 = df.dropna(subset = [\"matched_element\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b874798f-52cc-4fe2-80de-5459fb6c799a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177746d8-15c4-488a-a194-aedbe14dcd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.copy()\n",
    "\n",
    "# Here we put together a final dataset with both the treated and untreated individuals\n",
    "# Iterating over a pandas dataframe is painfully slow and not recommended, but we're working with tiny data here so it isn't a problem\n",
    "for _, row in df2.iterrows():\n",
    "    match_row = df.iloc[int(row['matched_element'])]\n",
    "    df3 = df3.append(match_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdb005d-8328-4746-b75d-dd3944225746",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158a479b-a9e2-4c23-b831-bf54b17f550b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['treat'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb975817-02f5-4cd3-bf66-945fdeaecbe3",
   "metadata": {},
   "source": [
    "## Fantastic, we now our matched dataset of 185 treated and 185 \"control\" participants. Now let's do some diagnostic work to ensure the matching worked well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2284698a-f90e-4995-b795-657ab7be889a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice how much more similar the two distributions are than before...\n",
    "\n",
    "sns.kdeplot(x = df3['pro_score'], hue = df3['treat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ad1b4b-e1f8-4aa4-a3f1-1e740dce098c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohenD (dataframe, column):\n",
    "    \"\"\"\n",
    "    Calculates Cohen’s D (a standard score that summarizes the difference in terms of the number of standard deviations).\n",
    "    \n",
    "    Args:\n",
    "        dataframe: the pandas dataframe of interest\n",
    "        column: the covariate name of interest\n",
    "        \n",
    "    Returns: a float corresponding to Cohen's D. Larger number indicates greater difference.\n",
    "    \"\"\"\n",
    "    treated_metric = dataframe[dataframe['treat'] == 1][column]\n",
    "    untreated_metric = dataframe[dataframe['treat'] == 0][column]\n",
    "    \n",
    "    d = (treated_metric.mean() - untreated_metric.mean()) / math.sqrt(\n",
    "        (\n",
    "            (treated_metric.count() - 1) * treated_metric.std() ** 2\n",
    "            + (untreated_metric.count() - 1) * untreated_metric.std() ** 2\n",
    "        )\n",
    "    / (treated_metric.count() + untreated_metric.count() - 2)\n",
    "    )\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20190e1-1d7d-41b7-8861-b468fad8df3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "cols = ['scaled_age', 'scaled_educ']\n",
    "for cl in cols:\n",
    "    data.append([cl,'before', cohenD(df,cl)])\n",
    "    data.append([cl,'after', cohenD(df3,cl)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662be5b9-7a9d-41eb-902f-9fb0a03b52bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(data, columns=['variable','matching','Cohen_D_difference'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d101746-7b33-484f-b5cd-95d83aca54dc",
   "metadata": {},
   "source": [
    "Notice that the two continuous covariates differ less between treatment and \"control\" groups after matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53edc12c-9b99-4a00-a4dd-08e63a96bd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_plot = sns.barplot(data = res, y = 'variable', x = 'Cohen_D_difference', hue = 'matching', orient='h')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a129fc5-5151-4068-a304-5697d3477234",
   "metadata": {},
   "source": [
    "Similarly, the proportion of positive values among binary covariates is closer after matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb887a5e-7bcb-4744-9aca-63560f65a7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "cols = ['educ', 'black', 'hisp', 'married']\n",
    "for cl in cols:\n",
    "    data.append([cl,'before', abs(df[df['treat'] == 1][cl].mean() - df[df['treat'] == 0][cl].mean())])\n",
    "    data.append([cl,'after', abs(df3[df3['treat'] == 1][cl].mean() - df3[df3['treat'] == 0][cl].mean())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95778ba-cfce-4f17-ad7b-e8f56f5041a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(data, columns=['variable','matching','abs_diff_in_class_proportion'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed4812b-e2e5-4a78-bd76-a77d47bb1c1e",
   "metadata": {},
   "source": [
    "For the most part, the differences in binary covariates between treated and untreated get smaller too after matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8621f17e-b600-41c2-bafb-a34b3defd3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_plot = sns.barplot(data = res, y = 'variable', x = 'abs_diff_in_class_proportion', hue = 'matching', orient='h')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad11dc3-4ac7-48d2-bd07-3c0f484add10",
   "metadata": {
    "tags": []
   },
   "source": [
    "## We can now calculate the Average Treatment Effect Among the Treated (ATT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125fe1e7-1a4f-4368-8724-87fa59e0ae27",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h3>EXERCISE: In the matched dataset with 185 treated and 185 untreated individuals, what is the treatment effect? Remember, this is the difference between the average outcome value in treated minus that of the untreated group.</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3677a95-d181-48a3-a139-26c18643f692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The PSM-corrected treatment effect is...\n",
    "# Hint: You'll want to use the `df3` dataframe, since this is the matched dataset of 185 treated and 185 untreated individuals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d24ea4-d22f-47ed-a57d-0fd4d3ab4c12",
   "metadata": {},
   "source": [
    "## Interesting, notice how it's less than the raw estimate! That is because there was some mild-to-moderate confounding occurring with the covariates we did propensity score matching on. This is the corrected estimate one would use if you had to estimate the causal effect and you couldn't simply run a proper experiment.\n",
    "\n",
    "#### If you really wanted to, you could obtain a confidence interval around this estimate. Like we did at the start of this notebook, you would need to repeat the following thousands of times and note the 2.5th and 97.5th percentile values of Average Treatment Effects Among the Treated:\n",
    "\n",
    "1) Draw a sample (of same size as your dataset) with replacement\n",
    "2) Generate a propensity score model and propensity score values\n",
    "3) Caliper match on them as we did above\n",
    "4) Calculate the ATT as you did in the cell above\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (intro-to-causal-inference)",
   "language": "python",
   "name": "intro-to-causal-inference"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
